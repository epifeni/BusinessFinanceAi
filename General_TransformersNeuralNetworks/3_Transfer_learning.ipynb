{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47f8bcef",
   "metadata": {},
   "source": [
    "## 3.2 Introduction to Pytorch - Transfer Learning and Hugging Face Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f662d583",
   "metadata": {},
   "source": [
    "Transfer Learning - A model trained for one task is reused as the starting point for a model for a second task\n",
    "1. Select a souce model from a repository of models\n",
    "2. Reuse the trained model\n",
    "\n",
    "Fine-tuning options for a Pre-Trained model:\n",
    "1. Update the whole model on labeled data plus any additional layers added on top (slowest - usually best performing)\n",
    "2. Freeze a subset fo the model, only updating the model slightly. Turn off the training on anything upto the xth encoder (faster than 1 - average performance)\n",
    "3. Freede the whole model and only train the additional layers added on of the pre-existing language model. Only update the feed-forward classifier that takes the output of the model and transforms it into a representation of our downstream task. The model will try it's best whith what it's already seen upto now (faster than 2 - usually worst performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6710ff",
   "metadata": {},
   "source": [
    "Process of fine-tuning a Model\n",
    "1. Training data: Use our training data to update the model\n",
    "2. Model: The model computes a loss function which indicates how wrong or right the model is at predecting the training data. \n",
    "    * Compute Loss is uses to compute gradients\n",
    "        * These gradients are used to optimze the weights which then updates the model as a whole\n",
    "3. This process continues in the training cycle until we are satisfied with the models performance\n",
    "Hugging Face Trainer API trainer takes care of the training loop (2 and 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc0aadf",
   "metadata": {},
   "source": [
    "#### Huggungface Trainer API Key Objects\n",
    "**Dataset** - Holds all data and splits into training/testing set<br>\n",
    "**DataCollator** - Forms batches of data from a Datasets<br>\n",
    "**TrainingArguments** - Keeps track of training arguments like saving strategy and learning rate scheduler patterns<br>\n",
    "**Trainer** - API to the Pytorch training loop for most starndard cases<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff8e0159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d1cc37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae33d962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor([0, 1, 2, 3, 4]) is torch.Size([5]) and dimension is 1\n"
     ]
    }
   ],
   "source": [
    "# 1-dimensional tensor\n",
    "\n",
    "one_d_tensor = torch.LongTensor([0, 1, 2, 3, 4]) # 1-D tensor with 5 elements\n",
    "\n",
    "print(f'Shape of {one_d_tensor} is {one_d_tensor.shape} and dimension is {one_d_tensor.dim()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8a66e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor([0, 1, 2]) is torch.Size([3]) and dimension is 1\n"
     ]
    }
   ],
   "source": [
    "# another 1-dimensional tensor\n",
    "\n",
    "one_d_tensor = torch.LongTensor([0, 1, 2])\n",
    "\n",
    "print(f'Shape of {one_d_tensor} is {one_d_tensor.shape} and dimension is {one_d_tensor.dim()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a503393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3])\n",
      "Shape of tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]]) is torch.Size([3, 3]) and dimension is 2\n"
     ]
    }
   ],
   "source": [
    "# 2-dimensional tensor\n",
    "\n",
    "two_d_tensor = torch.LongTensor([[0, 1, 2], [3, 4, 5], [6, 7, 8]]) # 2-D tensor with 3 rows and 3 columns. The shape is (3, 3)\n",
    "\n",
    "print(two_d_tensor.shape)\n",
    "\n",
    "print(f'Shape of {two_d_tensor} is {two_d_tensor.shape} and dimension is {two_d_tensor.dim()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbc1c06",
   "metadata": {},
   "source": [
    "#### unsqueeze and squeeze\n",
    "Used to convert tensors from one dimension to another dimension\n",
    "* unsqueeze forces a dimension to exist - specifies a batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e27b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor([0, 1, 2]) is torch.Size([3]) and dimension is 1\n",
      "Shape of tensor([[0, 1, 2]]) is torch.Size([1, 3]) and dimension is 2\n"
     ]
    }
   ],
   "source": [
    "one_d_tensor = torch.LongTensor([0, 1, 2])\n",
    "\n",
    "print(f'Shape of {one_d_tensor} is {one_d_tensor.shape} and dimension is {one_d_tensor.dim()}')\n",
    "\n",
    "# convert 1-dimensional tensor to 2-dimensional tensor by forcing a dimension in the front\n",
    "# this is useful when we want to force a \"batch\" dimension if we want to predict a single example\n",
    "two_d_tensor = one_d_tensor.unsqueeze(0) # change the dimension from 1-D to 2-D by adding a dimension in the front. Instead of shape (3,), the shape becomes (1, 3). The 1 idicates the batch dimension of a single data point that's being passed in\n",
    "\n",
    "print(f'Shape of {two_d_tensor} is {two_d_tensor.shape} and dimension is {two_d_tensor.dim()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4383f4ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28d80c25",
   "metadata": {},
   "source": [
    "#### Method for converting a tensor to a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b37e5b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert from pytorch to numpy\n",
    "\n",
    "two_d_tensor.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41f80bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert from pytorch to numpy with detach which removes a tensor from a computation graph (will be useful later)\n",
    "\n",
    "two_d_tensor.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab4ff7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
